{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09da274f",
   "metadata": {},
   "source": [
    "# Processing Pipeline - DeepGlobe Land Cover Classification\n",
    "\n",
    "This notebook builds the data preprocessing and input pipeline to prepare the DeepGlobe dataset for semantic segmentation model training and evaluation. It covers:\n",
    "- Train/validation split strategy\n",
    "- Image/mask transforms: normalization, resizing/tiling, and augmentations\n",
    "- Custom PyTorch Dataset and DataLoader\n",
    "- Handling class imbalance via class weights and/or sampling\n",
    "- Saving and visualizing pipeline outputs for sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e4c48",
   "metadata": {},
   "source": [
    "## 1.1 Create Train/Val Split\n",
    "\n",
    "**Objective:** Create a deterministic, stratified train/validation split for the DeepGlobe dataset.\n",
    "\n",
    "**Why this matters:**\n",
    "- Ensures reproducible experiments with a fixed random seed\n",
    "- Prevents data leakage between training and validation sets\n",
    "- Preserves class balance across splits via stratification\n",
    "- Produces shareable JSON indices for downstream training/evaluation\n",
    "\n",
    "This step analyzes each mask's dominant class and performs a stratified split, saving the resulting file lists to disk for consistent reuse.\n",
    "\n",
    "**File:** `src/data/create_splits.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d059400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dominant classes for stratification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [05:50<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split summary:\n",
      "  Total: 803 images\n",
      "  Train: 682 images (85.0%)\n",
      "  Val:   121 images (15.0%)\n",
      "\n",
      "✓ Splits saved to ../data/splits/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def rgb_to_class_id(mask_rgb: np.ndarray,\n",
    "                    color_map: Dict[Tuple[int, int, int], int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert RGB mask to class ID mask\n",
    "\n",
    "    Args:\n",
    "        mask_rgb: RGB mask array (H, W, 3)\n",
    "        color_map: Dictionary mapping RGB tuples to class IDs\n",
    "\n",
    "    Returns:\n",
    "        Class ID mask array (H, W)\n",
    "    \"\"\"\n",
    "    h, w = mask_rgb.shape[:2]\n",
    "    mask_id = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    for color, class_id in color_map.items():\n",
    "        match = np.all(mask_rgb == color, axis=-1)\n",
    "        mask_id[match] = class_id\n",
    "\n",
    "    return mask_id\n",
    "\n",
    "\n",
    "def get_dominant_class(mask_path, color_map):\n",
    "    \"\"\"Get the dominant (most frequent) class in a mask\"\"\"\n",
    "    mask_rgb = np.array(Image.open(mask_path))\n",
    "    mask_id = rgb_to_class_id(mask_rgb, color_map)\n",
    "\n",
    "    # Count pixels per class (excluding unknown)\n",
    "    class_counts = np.bincount(mask_id.flatten(), minlength=7)\n",
    "    class_counts[6] = 0  # Ignore unknown\n",
    "\n",
    "    return int(np.argmax(class_counts))\n",
    "\n",
    "\n",
    "def create_stratified_split(data_dir, val_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Create stratified train/val split\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to training data directory\n",
    "        val_ratio: Proportion for validation set\n",
    "        random_state: Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        train_files, val_files: Lists of file basenames\n",
    "    \"\"\"\n",
    "    COLOR_MAP = {\n",
    "        (0, 255, 255): 0, (255, 255, 0): 1, (255, 0, 255): 2,\n",
    "        (0, 255, 0): 3, (0, 0, 255): 4, (255, 255, 255): 5, (0, 0, 0): 6\n",
    "    }\n",
    "\n",
    "    # Get all image files\n",
    "    mask_paths = sorted(glob.glob(f\"{data_dir}/*_mask.png\"))\n",
    "    basenames = [Path(p).stem.replace('_mask', '') for p in mask_paths]\n",
    "\n",
    "    # Determine dominant class for each image\n",
    "    print(\"Analyzing dominant classes for stratification...\")\n",
    "    dominant_classes = []\n",
    "    for mask_path in tqdm(mask_paths):\n",
    "        dom_class = get_dominant_class(mask_path, COLOR_MAP)\n",
    "        dominant_classes.append(dom_class)\n",
    "\n",
    "    # Stratified split\n",
    "    train_names, val_names = train_test_split(\n",
    "        basenames,\n",
    "        test_size=val_ratio,\n",
    "        stratify=dominant_classes,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"\\nSplit summary:\")\n",
    "    print(f\"  Total: {len(basenames)} images\")\n",
    "    print(f\"  Train: {len(train_names)} images ({100*(1-val_ratio):.1f}%)\")\n",
    "    print(f\"  Val:   {len(val_names)} images ({100*val_ratio:.1f}%)\")\n",
    "\n",
    "    return train_names, val_names\n",
    "\n",
    "\n",
    "def save_splits(train_names, val_names, output_dir='../data/splits'):\n",
    "    \"\"\"Save split indices to JSON files\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(f'{output_dir}/train_files.json', 'w') as f:\n",
    "        json.dump(sorted(train_names), f, indent=2)\n",
    "\n",
    "    with open(f'{output_dir}/val_files.json', 'w') as f:\n",
    "        json.dump(sorted(val_names), f, indent=2)\n",
    "\n",
    "    print(f\"\\n✓ Splits saved to {output_dir}/\")\n",
    "\n",
    "\n",
    "train_names, val_names = create_stratified_split('../data/raw/train')\n",
    "save_splits(train_names, val_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
