{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7386cb8f",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a681f0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting training curves...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../outputs/checkpoints/training_history.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# ===== 1. Plot Training Curves =====\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlotting training curves...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mplot_training_curves\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../outputs/checkpoints/training_history.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../outputs/figures/training_curves.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ===== 2. Create Class Legend =====\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating class legend...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/mestrado/ml-deepglobe/src/utils/visualization.py:100\u001b[0m, in \u001b[0;36mplot_training_curves\u001b[0;34m(history_path, save_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mPlot training and validation curves from history\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    save_path: Path to save figure\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    101\u001b[0m     history \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    103\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../outputs/checkpoints/training_history.json'"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.utils.visualization import (\n",
    "    visualize_prediction, create_legend,\n",
    "    plot_training_curves, create_error_atlas\n",
    ")\n",
    "from src.training.metrics import SegmentationMetrics\n",
    "\n",
    "# ===== 1. Plot Training Curves =====\n",
    "print(\"Plotting training curves...\")\n",
    "plot_training_curves(\n",
    "    '../outputs/checkpoints/training_history.json',\n",
    "    save_path='../outputs/figures/training_curves.png'\n",
    ")\n",
    "\n",
    "# ===== 2. Create Class Legend =====\n",
    "print(\"Creating class legend...\")\n",
    "create_legend(save_path='../outputs/figures/class_legend.png')\n",
    "\n",
    "# ===== 3. Evaluate on Validation Set =====\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.dataset import DeepGlobeDataset\n",
    "from src.models.segmentation_model import create_model\n",
    "from src.utils.torch_device import get_device\n",
    "\n",
    "# Load model\n",
    "device = get_device()\n",
    "model = create_model(architecture='unet', encoder='resnet34', num_classes=7)\n",
    "checkpoint = torch.load('../outputs/checkpoints/best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load validation data\n",
    "with open('../data/splits/val_files.json') as f:\n",
    "    val_files = json.load(f)\n",
    "\n",
    "val_dataset = DeepGlobeDataset(\n",
    "    data_dir='../data/raw/train',\n",
    "    file_list=val_files,\n",
    "    transform=DeepGlobeDataset.get_val_transforms(),\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# Compute metrics\n",
    "metrics_tracker = SegmentationMetrics(num_classes=7, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in val_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        metrics_tracker.update(outputs, masks)\n",
    "\n",
    "final_metrics = metrics_tracker.compute()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL VALIDATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"mIoU: {final_metrics['mIoU']:.4f}\")\n",
    "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "print(\"\\nPer-class IoU:\")\n",
    "for key, value in final_metrics.items():\n",
    "    if key.startswith('IoU_'):\n",
    "        class_name = key.replace('IoU_', '')\n",
    "        print(f\"  {class_name:12s}: {value:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===== 4. Visualize Sample Predictions =====\n",
    "print(\"\\nVisualizing sample predictions...\")\n",
    "\n",
    "# Get a few validation samples\n",
    "sample_indices = [0, 100, 200, 300, 400]\n",
    "\n",
    "for idx in sample_indices:\n",
    "    image_tensor, mask = val_dataset[idx]\n",
    "\n",
    "    # Denormalize image\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    image = (image_tensor * std + mean).permute(1, 2, 0).numpy()\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor.unsqueeze(0).to(device))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Visualize\n",
    "    visualize_prediction(\n",
    "        image,\n",
    "        mask.numpy(),\n",
    "        pred,\n",
    "        save_path=f'../outputs/figures/prediction_sample_{idx}.png',\n",
    "        title=f'Validation Sample {idx}'\n",
    "    )\n",
    "\n",
    "print(\"\\n☑️ Evaluation completed!\")\n",
    "print(\"Check outputs/figures/ for visualizations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
