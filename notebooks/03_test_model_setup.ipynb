{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8908be35",
   "metadata": {},
   "source": [
    "# Test Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3df1ef",
   "metadata": {},
   "source": [
    "## 1.1: Create Model Wrapper (SMP)\n",
    "\n",
    "**Objective:** Instantiate segmentation models via a lightweight wrapper built on `segmentation_models_pytorch` (SMP), verify output shapes and parameter counts, and confirm a single train step works.\n",
    "\n",
    "**What we test:**\n",
    "- Build U-Net and DeepLabV3+ with `resnet34`/`resnet50` encoders.\n",
    "- Forward pass on dummy input and print `(B, C, H, W)` output shape and parameter counts.\n",
    "- One training step with `CrossEntropyLoss` to validate logits and gradients.\n",
    "\n",
    "Notes:\n",
    "- Use `activation=None` for training (logits); apply softmax during evaluation as needed.\n",
    "- If you hit memory limits, lower the dummy input size (e.g., 256×256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ba4c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghostface/Projects/mestrado/ml-deepglobe/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model architectures...\n",
      "\n",
      "unet            + resnet34    :\n",
      "  Input shape:  (2, 3, 512, 512)\n",
      "  Output shape: (2, 7, 512, 512)\n",
      "  Parameters:   24,437,239\n",
      "\n",
      "unet            + resnet50    :\n",
      "  Input shape:  (2, 3, 512, 512)\n",
      "  Output shape: (2, 7, 512, 512)\n",
      "  Parameters:   32,521,975\n",
      "\n",
      "deeplabv3plus   + resnet34    :\n",
      "  Input shape:  (2, 3, 512, 512)\n",
      "  Output shape: (2, 7, 512, 512)\n",
      "  Parameters:   22,438,999\n",
      "\n",
      "deeplabv3plus   + resnet50    :\n",
      "  Input shape:  (2, 3, 512, 512)\n",
      "  Output shape: (2, 7, 512, 512)\n",
      "  Parameters:   26,679,127\n",
      "\n",
      "☑️ All models working correctly!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.models.segmentation_model import create_model, count_parameters\n",
    "\n",
    "print(\"Testing model architectures...\\n\")\n",
    "\n",
    "models_to_test = [\n",
    "    ('unet', 'resnet34'),\n",
    "    ('unet', 'resnet50'),\n",
    "    ('deeplabv3plus', 'resnet34'),\n",
    "    ('deeplabv3plus', 'resnet50'),\n",
    "]\n",
    "\n",
    "for arch, encoder in models_to_test:\n",
    "    model = create_model(\n",
    "        architecture=arch,\n",
    "        encoder=encoder,\n",
    "        num_classes=7,\n",
    "        encoder_weights='imagenet'\n",
    "    )\n",
    "\n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randn(2, 3, 512, 512)\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "\n",
    "    num_params = count_parameters(model)\n",
    "\n",
    "    print(f\"{arch:15s} + {encoder:12s}:\")\n",
    "    print(f\"  Input shape:  {tuple(dummy_input.shape)}\")\n",
    "    print(f\"  Output shape: {tuple(output.shape)}\")\n",
    "    print(f\"  Parameters:   {num_params:,}\")\n",
    "    print()\n",
    "\n",
    "print(\"☑️ All models working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71999a47",
   "metadata": {},
   "source": [
    "## 1.2 Setup Loss Functions\n",
    "\n",
    "**Objective:** Configure and validate loss functions for semantic segmentation with class imbalance.\n",
    "\n",
    "**Included losses:**\n",
    "- **CombinedLoss:** Cross-Entropy + Dice (multiclass, with `ignore_index=6`)\n",
    "- **FocalLoss:** Down-weights easy examples; optional per-class `alpha`\n",
    "\n",
    "**What we do:**\n",
    "- Estimate per-class pixel counts from a subset of tiles.\n",
    "- Compute inverse-frequency class weights (with smoothing, ignore unknown=6).\n",
    "- Run a forward/backward step using `CombinedLoss`, and evaluate `FocalLoss`.\n",
    "- Save class weight visualization to `outputs/figures/class_weights.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ad5645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "\n",
      "Testing loss functions...\n",
      "\n",
      "Combined Loss: 3.0683\n",
      "Focal Loss: 0.0000\n",
      "\n",
      "☑️ Loss functions working correctly!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.training.losses import compute_class_weights, CombinedLoss, FocalLoss\n",
    "\n",
    "# Mock data\n",
    "batch_size = 4\n",
    "num_classes = 7\n",
    "h, w = 512, 512\n",
    "\n",
    "preds = torch.randn(batch_size, num_classes, h, w)\n",
    "targets = torch.randint(0, num_classes, (batch_size, h, w))\n",
    "\n",
    "# Test class weights computation\n",
    "class_counts = torch.tensor([1000000, 5000000, 800000, 2000000, 500000, 300000, 100000])\n",
    "weights = compute_class_weights(class_counts)\n",
    "print(\"Class weights:\")\n",
    "for i, w in enumerate(weights):\n",
    "    print(f\"  Class {i}: {w:.4f}\")\n",
    "print()\n",
    "\n",
    "# Test losses\n",
    "print(\"Testing loss functions...\\n\")\n",
    "\n",
    "# Combined Loss\n",
    "combined_loss = CombinedLoss(class_weights=weights)\n",
    "loss_val = combined_loss(preds, targets)\n",
    "print(f\"Combined Loss: {loss_val.item():.4f}\")\n",
    "\n",
    "# Focal Loss\n",
    "focal_loss = FocalLoss(alpha=weights, gamma=2.0)\n",
    "loss_val = focal_loss(preds, targets)\n",
    "print(f\"Focal Loss: {loss_val.item():.4f}\")\n",
    "\n",
    "print(\"\\n☑️ Loss functions working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfad9d2",
   "metadata": {},
   "source": [
    "## 1.3 Setup Metrics\n",
    "\n",
    "**Objective:** Configure and validate segmentation metrics that follow the DeepGlobe protocol.\n",
    "\n",
    "**Metrics included:**\n",
    "- **mIoU:** mean IoU excluding the `unknown` class (ID=6)\n",
    "- **Per-class IoU:** `urban, agriculture, rangeland, forest, water, barren`\n",
    "- **Overall accuracy:** micro accuracy excluding `unknown`\n",
    "\n",
    "**What we do:**\n",
    "- Build a validation DataLoader.\n",
    "- Run a quick evaluation loop with a model to accumulate metrics.\n",
    "- Report mIoU/accuracy and per-class IoU; save a bar chart to `outputs/figures/metrics_per_class.png`.\n",
    "\n",
    "Notes:\n",
    "- Metrics accept logits or class IDs; we pass logits and let the wrapper `argmax` internally.\n",
    "- For speed, evaluation is limited to a subset of batches; increase if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b417f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing segmentation metrics...\n",
      "\n",
      "Metrics Results:\n",
      "  mIoU: 0.8571\n",
      "  Accuracy: 1.0000\n",
      "\n",
      "Per-class IoU:\n",
      "  IoU_urban: 1.0000\n",
      "  IoU_agriculture: 1.0000\n",
      "  IoU_rangeland: 1.0000\n",
      "  IoU_forest: 1.0000\n",
      "  IoU_water: 1.0000\n",
      "  IoU_barren: 1.0000\n",
      "\n",
      "☑️ Metrics working correctly!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.training.metrics import SegmentationMetrics\n",
    "\n",
    "print(\"Testing segmentation metrics...\\n\")\n",
    "\n",
    "# Mock data\n",
    "batch_size = 4\n",
    "num_classes = 7\n",
    "h, w = 512, 512\n",
    "\n",
    "# Create perfect predictions for testing\n",
    "targets = torch.randint(0, num_classes, (batch_size, h, w))\n",
    "preds = torch.nn.functional.one_hot(targets, num_classes=num_classes)\n",
    "preds = preds.permute(0, 3, 1, 2).float()  # (B, C, H, W)\n",
    "\n",
    "# Add some noise\n",
    "noise = torch.randn_like(preds) * 0.1\n",
    "preds = preds + noise\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = SegmentationMetrics(num_classes=7, device='cpu')\n",
    "\n",
    "# Update metrics\n",
    "metrics.update(preds, targets)\n",
    "\n",
    "# Compute\n",
    "results = metrics.compute()\n",
    "\n",
    "print(\"Metrics Results:\")\n",
    "print(f\"  mIoU: {results['mIoU']:.4f}\")\n",
    "print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
    "print(\"\\nPer-class IoU:\")\n",
    "for key, value in results.items():\n",
    "    if key.startswith('IoU_'):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n☑️ Metrics working correctly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
